# ğŸ“Š SIEM Log Collectors

**Coletores de ingestÃ£o histÃ³rica para migraÃ§Ã£o de SIEMs legados para o Microsoft Sentinel.**

Cada coletor extrai logs do SIEM de origem via API REST, gera relatÃ³rios de volume (CSV + TXT) e armazena mÃ©tricas em SQLite â€” tudo isso para dimensionar corretamente o workspace do Sentinel antes da migraÃ§Ã£o.

---

## ğŸ¯ Para que serve?

Quando vocÃª estÃ¡ migrando de um SIEM (QRadar, Splunk, etc.) para o **Microsoft Sentinel**, a primeira pergunta Ã©:

> _"Quantos GB/dia eu ingiro por log source? Qual o tamanho do meu ambiente?"_

Esses coletores respondem essa pergunta automaticamente, gerando um relatÃ³rio detalhado de volume por log source type, pronto para importar no Excel e calcular o custo do Sentinel.

---

## ğŸ“‹ Matriz de SIEMs Suportados

| SIEM | Status | Pasta | API | Testes |
|------|--------|-------|-----|--------|
| **IBM QRadar** | âœ… Pronto | [`collectors/qradar/`](collectors/qradar/) | REST API v26.0 (AQL + Ariel) | 18 testes |
| **Splunk Enterprise** | âœ… Pronto | [`collectors/splunk/`](collectors/splunk/) | REST API v2 (SPL + Search Jobs) | 24 testes |
| **Google SecOps** | âœ… Pronto | [`collectors/google_secops/`](collectors/google_secops/) | Backstory API v1 (UDM Search) | 45 testes |
| **Core Compartilhado** | âœ… Pronto | [`core/`](core/) | â€” | 40 testes |
| **Elastic Security** | ğŸ“‹ Planejado | â€” | Elasticsearch API | â€” |

---

## ğŸ—ï¸ Arquitetura Modular

O projeto utiliza uma **arquitetura modular** com cÃ³digo compartilhado em `core/` e mÃ³dulos SIEM-especÃ­ficos em `collectors/`:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚        main.py (Unified Entry Point)        â”‚
â”‚  python main.py qradar --url ... --token .. â”‚
â”‚  python main.py splunk --url ... --token .. â”‚
â”‚  python main.py secops --sa-file ... --rg.. â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚        core/ (Shared Modules)               â”‚
â”‚  â”œâ”€â”€ utils.py      ErrorCounter, retry,     â”‚
â”‚  â”‚                 signal handlers          â”‚
â”‚  â”œâ”€â”€ db.py         MetricsDB (SQLite)       â”‚
â”‚  â”œâ”€â”€ report.py     ReportGenerator (CSV+TXT)â”‚
â”‚  â””â”€â”€ collection.py run_collection_cycle,    â”‚
â”‚                    main_collection_loop      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚        collectors/ (SIEM-specific)          â”‚
â”‚  â”œâ”€â”€ base.py       SIEMClient ABC           â”‚
â”‚  â”œâ”€â”€ qradar/       QRadarClient (AQL)       â”‚
â”‚  â”œâ”€â”€ splunk/       SplunkClient (SPL)       â”‚
â”‚  â””â”€â”€ google_secops/ GoogleSecOpsClient(UDM) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### CaracterÃ­sticas comuns

| Feature | Detalhe |
|---------|---------|
| **Janelas de 1h** | Coleta hora a hora para granularidade e resiliÃªncia |
| **Zero-fill** | Registra `0 bytes` para janelas sem eventos (evita buracos no relatÃ³rio) |
| **Catch-up cap** | MÃ¡ximo 3 janelas por ciclo ao recuperar atraso |
| **Retry com backoff** | 3 tentativas com espera exponencial (2s â†’ 4s â†’ 8s) |
| **Parada graciosa** | Ctrl+C salva estado no SQLite â€” retoma de onde parou |
| **RelatÃ³rio CSV** | Pronto para Excel com BOM UTF-8 e separador `;` |
| **MÃ©tricas SQLite** | Banco local sobrevive a quedas e permite re-geraÃ§Ã£o de relatÃ³rios |
| **collection_days** | PadrÃ£o 6 dias (evita "dia parcial" nas mÃ©dias) |
| **GROUP BY id** | Agrupamento por `logsource_id` (evita mistura se fontes tiverem nomes iguais ou forem renomeadas) |
| **Falha â‰  avanÃ§a** | Se a query falha, a janela **nÃ£o avanÃ§a** â€” catch-up automÃ¡tico no prÃ³ximo ciclo |
| **Status tracking** | Corridas com falha sÃ£o marcadas como `status='failed'` no banco |
| **Enabled-only zero-fill** | Apenas fontes com `enabled=1` participam do zero-fill |
| **Ariel results limit** | MÃ¡ximo 50.000 resultados por query AQL; warning se atingido |
| **SPL results limit** | MÃ¡ximo 10.000 resultados por query SPL; warning se atingido |
| **logsource_id estÃ¡vel** | Splunk e SecOps usam SHA-256 (`_stable_id()`) em vez de `hash()` â€” IDs determinÃ­sticos entre reinÃ­cios |
| **NOTAS por SIEM** | SeÃ§Ã£o NOTAS no relatÃ³rio .txt com texto especÃ­fico por SIEM (bytes, coalescing, limitaÃ§Ãµes) |

### âš ï¸ Trade-off: Catch-up cap

ApÃ³s falhas consecutivas de conexÃ£o, o coletor tenta recuperar ("catch-up") a janela de tempo perdida. PorÃ©m, para evitar queries AQL/SPL gigantes que sobrecarregariam o SIEM, existe um **cap de seguranÃ§a** (`MAX_CATCHUP_WINDOWS = 3`):

- Se o gap acumulado for **â‰¤ 3Ã— o intervalo** (ex: â‰¤ 3h com intervalo de 1h), o catch-up coleta toda a janela perdida normalmente.
- Se o gap **exceder 3Ã— o intervalo**, a janela Ã© recortada e **os dados do perÃ­odo mais antigo sÃ£o descartados**. O coletor registra o range perdido no log e segue em frente.

**Isso Ã© intencional:** prioriza-se "andar para frente" com dados recentes em vez de tentar um backfill total que poderia causar timeout ou erro de memÃ³ria no SIEM. Se precisar de backfill completo, ajuste `MAX_CATCHUP_WINDOWS` em `core/utils.py` ou execute o coletor com janela retroativa manual.

---

## ğŸš€ Quick Start

### 1. Clone o repositÃ³rio

```bash
git clone https://github.com/lsardim1/siem-log-collectors.git
cd siem-log-collectors
pip install -r requirements.txt
```

### 2. Execute o coletor

```bash
# QRadar
python main.py qradar --url https://qradar:443 --token SEU_TOKEN

# Splunk (Bearer Token)
python main.py splunk --url https://splunk:8089 --token SEU_TOKEN

# Splunk (Basic Auth)
python main.py splunk --url https://splunk:8089 --username admin --password SENHA

# Google SecOps (Service Account)
python main.py secops --sa-file /path/to/sa.json --region us

# Google SecOps (Bearer Token)
python main.py secops --token $(gcloud auth print-access-token) --region southamerica-east1

# Gerar apenas relatÃ³rio de DB existente
python main.py qradar --report-only --db-file qradar_metrics.db

# Criar config de exemplo
python main.py splunk --create-config
```

### 3. Confira os relatÃ³rios

```
reports/
â”œâ”€â”€ <siem>_daily_report_YYYYMMDD_HHMMSS.csv    â† Detalhamento diÃ¡rio (Excel-ready)
â”œâ”€â”€ <siem>_summary_report_YYYYMMDD_HHMMSS.csv  â† MÃ©dia diÃ¡ria por source
â””â”€â”€ <siem>_full_report_YYYYMMDD_HHMMSS.txt     â† Resumo completo em texto
```

---

## ğŸ§ª Rodando os Testes

Todos os 127 testes rodam offline com `unittest.mock`:

```bash
python -m unittest discover tests/ -v
```

> **Nota:** NÃ£o Ã© necessÃ¡rio ter QRadar, Splunk ou Google SecOps para rodar os testes.

---

## ğŸ“ Estrutura do RepositÃ³rio

```
siem-log-collectors/
â”œâ”€â”€ main.py                      â† Entry point unificado
â”œâ”€â”€ requirements.txt             â† DependÃªncias (requests, urllib3)
â”œâ”€â”€ README.md                    â† VocÃª estÃ¡ aqui
â”œâ”€â”€ LICENSE                      â† MIT
â”œâ”€â”€ CONTRIBUTING.md              â† Como contribuir / adicionar novo SIEM
â”œâ”€â”€ core/                        â† MÃ³dulos compartilhados
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ utils.py                 â† ErrorCounter, retry, signal handlers
â”‚   â”œâ”€â”€ db.py                    â† MetricsDB (SQLite)
â”‚   â”œâ”€â”€ report.py                â† ReportGenerator (CSV + TXT)
â”‚   â””â”€â”€ collection.py            â† run_collection_cycle, main_loop
â”œâ”€â”€ collectors/                  â† MÃ³dulos SIEM-especÃ­ficos
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ base.py                  â† SIEMClient ABC (interface)
â”‚   â”œâ”€â”€ qradar/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ client.py            â† QRadarClient (AQL, Ariel)
â”‚   â”‚   â””â”€â”€ README.md
â”‚   â”œâ”€â”€ splunk/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ client.py            â† SplunkClient (SPL, Search Jobs v2)
â”‚   â”‚   â””â”€â”€ README.md
â”‚   â””â”€â”€ google_secops/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ client.py            â† GoogleSecOpsClient (UDM Search)
â”‚       â””â”€â”€ README.md
â”œâ”€â”€ tests/                       â† SuÃ­te de testes unificada
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ conftest.py
â”‚   â”œâ”€â”€ test_core.py             â† 40 testes (shared modules)
â”‚   â”œâ”€â”€ test_qradar.py           â† 18 testes (QRadar client)
â”‚   â”œâ”€â”€ test_splunk.py           â† 24 testes (Splunk client)
â”‚   â””â”€â”€ test_google_secops.py    â† 45 testes (Google SecOps client)
â””â”€â”€ docs/
    â””â”€â”€ architecture.md          â† Detalhes da arquitetura modular
```

---

## ğŸ¤ Contribuindo

Quer adicionar suporte a um novo SIEM? Veja o [CONTRIBUTING.md](CONTRIBUTING.md) com o passo a passo e o template de coletor.

---

## ğŸ“ LicenÃ§a

Este projeto estÃ¡ licenciado sob a [MIT License](LICENSE).

---

## ğŸ’¡ Dicas

- **tmux/screen:** Para coletas longas (6+ dias), rode dentro de um `tmux` ou `screen` para nÃ£o perder a sessÃ£o SSH.
- **Ctrl+C seguro:** A coleta pode ser interrompida a qualquer momento â€” o estado Ã© salvo no SQLite e retomado na prÃ³xima execuÃ§Ã£o.
- **Excel:** Abra o CSV no Excel com "Dados â†’ De Texto/CSV" para manter a codificaÃ§Ã£o UTF-8 correta.
- **Sizing do Sentinel:** Use as colunas `avg_gb_per_day` e `peak_gb_per_day` do CSV para calcular o custo no [Azure Pricing Calculator](https://azure.microsoft.com/pricing/calculator/).
