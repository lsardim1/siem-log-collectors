# üèóÔ∏è Arquitetura dos Coletores

Este documento detalha a arquitetura modular do projeto **siem-log-collectors**.

---

## Vis√£o Geral

O projeto utiliza uma arquitetura modular onde c√≥digo compartilhado vive em `core/` e cada SIEM tem apenas o c√≥digo espec√≠fico da sua API em `collectors/<siem>/client.py`. Um entry point unificado (`main.py`) orquestra a execu√ß√£o.

```
                    main.py
                      ‚îÇ
         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
         ‚îÇ                         ‚îÇ                 ‚îÇ
    qradar subcommand         splunk subcommand  secops subcommand
         ‚îÇ                         ‚îÇ                 ‚îÇ
         ‚ñº                         ‚ñº                 ‚ñº
  QRadarClient              SplunkClient     GoogleSecOpsClient
  (AQL + Ariel)             (SPL + Search    (UDM Search +
         ‚îÇ                  Jobs v2)          Backstory API)
         ‚îÇ                         ‚îÇ                 ‚îÇ
         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                  ‚îÇ
         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
         ‚îÇ        ‚îÇ        ‚îÇ
    core/utils  core/db  core/report
    (retry,     (SQLite) (CSV+TXT)
     signals)      ‚îÇ
                   ‚îÇ
              core/collection
              (cycle engine)
```

---

## Componentes

### 1. `core/utils.py` ‚Äî Utilit√°rios Compartilhados

- **ErrorCounter:** Contador de erros por categoria
- **_retry_with_backoff():** Retry exponencial (2s ‚Üí 4s ‚Üí 8s) com suporte a Retry-After
- **Signal handlers:** Parada graciosa via SIGINT/SIGTERM
- **Constantes:** `DEFAULT_COLLECTION_DAYS=6`, `MAX_CATCHUP_WINDOWS=3`, `RETRYABLE_HTTP_STATUSES`

### 2. `core/db.py` ‚Äî MetricsDB (SQLite)

Banco local unificado com tr√™s tabelas:

| Tabela | Chaves | Descri√ß√£o |
|--------|--------|-----------|
| `collection_runs` | `run_id` (PK) | Registro de cada execu√ß√£o de coleta (status: `success`/`failed`) |
| `event_metrics` | `id` (PK), FK `run_id` | M√©tricas por log source por janela |
| `log_sources_inventory` | `logsource_id` (PK) | Invent√°rio de sources/indexes |

Formato unificado para invent√°rio:
```python
{"logsource_id": int, "name": str, "type_name": str,
 "type_id": int, "enabled": bool, "description": str}
```

### 3. `core/report.py` ‚Äî ReportGenerator

Gera relat√≥rios parametrizados por SIEM:

| Par√¢metro | QRadar | Splunk | Google SecOps |
|-----------|--------|--------|---------------|
| `siem_name` | `"qradar"` | `"splunk"` | `"secops"` |
| `source_label` | `"Log Source"` | `"Source [Index]"` | `"Log Type"` |
| `type_label` | `"Tipo Log Source"` | `"Sourcetype"` | `"Log Type"` |
| `include_unparsed` | ‚úÖ | ‚ùå | ‚ùå |
| `include_aggregated` | ‚úÖ | ‚ùå | ‚ùå |

Formatos:
- **CSV** ‚Äî UTF-8 BOM, separador `;`, Excel-ready
- **TXT** ‚Äî Tabela formatada com resumo di√°rio e estimativa mensal

### 4. `core/collection.py` ‚Äî Collection Engine

- `run_collection_cycle()` ‚Äî executa um ciclo para uma janela exata. Retorna n√∫mero de sources com dados (‚â• 0) ou **-1 em caso de falha na query** (sinaliza ao loop para n√£o avan√ßar a janela)
- `main_collection_loop()` ‚Äî loop principal com invent√°rio, coleta, catch-up e relat√≥rio. S√≥ avan√ßa `last_window_end_ms` quando `ds_count >= 0`

Features:
- **Janelas cont√≠guas de 1h** `[start, end)` ‚Äî sem sobreposi√ß√£o
- **Catch-up cap** ‚Äî m√°ximo `MAX_CATCHUP_WINDOWS=3` janelas por ciclo
- **Zero-fill** ‚Äî registra `0` para sources sem eventos na janela- **GROUP BY logsource_id** ‚Äî evita mistura quando fontes t√™m nomes iguais ou s√£o renomeadas
- **Falha ‚â† avan√ßa** ‚Äî query failure retorna -1; a janela √© re-tentada no pr√≥ximo ciclo
- **Status tracking** ‚Äî runs com falha s√£o marcadas `status='failed'` via `update_collection_run_status()`
- **Enabled-only zero-fill** ‚Äî apenas fontes com `enabled=1` participam do zero-fill (fontes desabilitadas s√£o exclu√≠das)
- **post_collect_callback** ‚Äî Splunk usa para atualizar invent√°rio de SPL results

### 5. `collectors/base.py` ‚Äî SIEMClient ABC

Interface que todo client SIEM deve implementar:

```python
class SIEMClient(ABC):
    def test_connection(self) -> Dict: ...
    def get_event_metrics_window(self, start_ms, end_ms) -> Optional[List[Dict]]: ...
```

### 6. `collectors/qradar/client.py` ‚Äî QRadarClient

- **Auth:** SEC token via header
- **Queries:** AQL via `/api/ariel/searches` (async polling)
- **Invent√°rio:** `/api/config/event_sources/log_source_management/`
- **Pagina√ß√£o:** Range headers (`ARIEL_MAX_RESULTS=50000`; warning se atingido)
- **Coalescing Ratio:** Relat√≥rios incluem coluna com ratio `total_events / aggregated_events` (indica coalescing do QRadar)
- **Bytes:** Volumes de bytes referem-se ao **payload armazenado no Ariel** (pode diferir do log bruto on-wire)
- **Unparsed:** `isunparsed` via AQL com fallback

### 7. `collectors/splunk/client.py` ‚Äî SplunkClient

- **Auth:** Bearer Token ou Basic Auth (username:password)
- **Queries:** SPL via Search Jobs API v2
- **Invent√°rio:** `/services/data/indexes` + SPL metadata
- **Extras:** license_usage.log, forwarder list, data inputs via `| rest`

### 8. `collectors/google_secops/client.py` ‚Äî GoogleSecOpsClient

- **Auth:** Service Account JSON (`google-auth`) ou Bearer Token
- **Scope:** `https://www.googleapis.com/auth/chronicle-backstory`
- **API:** Backstory API v1 ‚Äî `GET /v1/events:udmSearch`
- **Endpoints:** 19 regi√µes (US default: `backstory.googleapis.com`)
- **Agrega√ß√£o:** Client-side por `metadata.logType` + `metadata.productName`
- **Limite:** 10.000 eventos/query, 360 queries/hora, 10 min timeout
- **Invent√°rio:** Log types descobertos via UDM Search (√∫ltimas 24h)
- **Nota:** Payload bytes n√£o dispon√≠veis via UDM Search (preenchidos com 0.0)

### 9. `main.py` ‚Äî Entry Point Unificado

```bash
python main.py qradar --url ... --token ...
python main.py splunk --url ... --token ...
python main.py splunk --url ... --username ... --password ...
python main.py secops --sa-file ... --region us
python main.py secops --token ... --region southamerica-east1
python main.py qradar --report-only --db-file metrics.db
python main.py splunk --create-config
```

---

## Fluxo de Dados

```
SIEM API ‚îÄ‚îÄ‚ñ∫ SIEMClient ‚îÄ‚îÄ‚ñ∫ run_collection_cycle ‚îÄ‚îÄ‚ñ∫ MetricsDB (SQLite)
                                                          ‚îÇ
                                                          ‚ñº
                                                    ReportGenerator
                                                     ‚îÇ          ‚îÇ
                                                     ‚ñº          ‚ñº
                                                    CSV        TXT
                                                (Excel)    (Terminal)
```

---

## Tratamento de Erros

| Cen√°rio | Comportamento |
|---------|---------------|
| API timeout | Retry com backoff (2s ‚Üí 4s ‚Üí 8s) |
| HTTP 401/403 | Erro fatal ‚Äî token inv√°lido |
| HTTP 429 | Retry respeitando `Retry-After` header |
| HTTP 5xx | Retry com backoff |
| Rede indispon√≠vel | Retry com backoff |
| Ctrl+C / SIGINT | Parada graciosa ‚Äî salva estado e gera relat√≥rio |
| Query AQL/SPL/UDM falha | Retorna -1; janela n√£o avan√ßa; catch-up no pr√≥ximo ciclo |
| SIEM reiniciando | Retry com backoff ‚Äî recupera nas janelas seguintes |
| Rate limit (429) | Retry respeitando `Retry-After`; Google SecOps: 360 QPH |
| Disco cheio | Erro fatal ‚Äî SQLite n√£o consegue escrever |

---

## Como Adicionar um Novo SIEM

1. Crie `collectors/<nome>/client.py` com uma classe que herda de `SIEMClient`
2. Implemente `test_connection()` e `get_event_metrics_window()`
3. Adicione `collect_inventory()` e `create_sample_config()`
4. Adicione o subcommand em `main.py`
5. Crie `tests/test_<nome>.py` com testes unit√°rios
6. Atualize `README.md`
